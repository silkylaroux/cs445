{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Classification with QDA, LDA, and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damian Armijo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will make a new version of your ```NeuralNetwork``` class called ```NeuralNetworkClassifier```. You will then apply ```QDA```, ```LDA``` and your ```NeuralNetworkClassifier``` to a classification problem and discuss the results.  The ```tanh``` function will be used as the activation function for ```NeuralNetworkClassifier```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralNetworkClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy your ```neuralnetworksA2.py``` into a new file named ```neuralnetworksA4.py```.  Define a new class named ```NeuralNetworkClassifier``` that extends ```NeuralNetwork```.  The following code cell indicates which methods you must override, with comments instructing you what you must do to complete it.  Add this class to your ```neuralnetworksA4.py``` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetworkClassifier(NeuralNetwork):\n",
    "\n",
    "    def _multinomialize(self, Y):   # also known as softmax\n",
    "        # fix to avoid overflow\n",
    "        mx = max(0, np.max(Y))\n",
    "        expY = np.exp(Y - mx)\n",
    "        denom = np.sum(expY, axis=1).reshape((-1, 1)) + sys.float_info.epsilon\n",
    "        return expY / denom\n",
    "\n",
    "    def _objectiveF(self, w, X, Tindicators):\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "        # Convert Y to multinomial distribution. Call result G.\n",
    "        #  and return negative of mean log likelihood.\n",
    "        # Write the call to np.log as  np.log(G + sys.float_info.epsilon)\n",
    "\n",
    "\n",
    "    def _gradientF(self, w, X, Tindicators):\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "        # Convert Y to multinomial distribution. Call result G.\n",
    "        # delta calculated as before, except use Tindicators instead of T to\n",
    "        #   make error of  Tindicates - G\n",
    "        # Also, negate the result.  Why?\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "\n",
    "    def train(self, X, T, nIterations=100, verbose=False,\n",
    "              weightPrecision=0, errorPrecision=0, saveWeightsHistory=False):\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "        # Remove T standardization calculations\n",
    "        # Assign to Tindicators using ml.makeIndicatorVars\n",
    "        # Add   self.classes = np.unique(T)\n",
    "        # Pass Tindicators into ml.scg instead of T\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "\n",
    "    def use(self, X, allOutputs=False):\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "        # multinomialize Y, assign to G\n",
    "        # Calculate predicted classes by\n",
    "        #   picking argmax for each row of G\n",
    "        #   and use the results to index into self.classes.\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "        return (classes, G, Z[1:]) if allOutputs else classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (neuralnetworksA4.py, line 203)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/home/leoric/Documents/damian/CS445/cs445/A4/neuralnetworksA4.py\"\u001b[0;36m, line \u001b[0;32m203\u001b[0m\n\u001b[0;31m    .\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import neuralnetworksA4 as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.arange(10).reshape((-1, 1))\n",
    "T = np.array([1]*5 + [2]*5).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(1, [5, 5], 2)\n",
      "   Network was trained for 21 iterations that took 0.0728 seconds. Final error is 0.007611063152805585.\n",
      "T, Predicted\n",
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "netc = nn.NeuralNetworkClassifier(X.shape[1], [5, 5], len(np.unique(T)))\n",
    "netc.train(X, T, 20)\n",
    "print(netc)\n",
    "print('T, Predicted')\n",
    "print(np.hstack((T, netc.use(X))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addition to ```partition``` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the keyword parameter ```classification``` with a default value of ```False``` to your ```partition``` function.  When its value is set to ```True``` your ```partition``` function must perform a stratified partitioning as illustrated in lecture notes [12 Introduction to Classification](http://nbviewer.ipython.org/url/www.cs.colostate.edu/~anderson/cs445/notebooks/12%20Introduction%20to%20Classification.ipynb)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-676539e7bfd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmlutilities\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leoric/Documents/damian/CS445/cs445/A4/mlutilities.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpltpatch\u001b[0m  \u001b[0;31m# for Arc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpltcoll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import mlutilities as ml\n",
    "Xtrain, Ttrain, Xtest, Ttest = ml.partition(X, T, 0.6, classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ttrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [4],\n",
       "       [8],\n",
       "       [9]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ttest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add these two functions to your ```mlutilities.py``` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusionMatrix(actual, predicted, classes):\n",
    "    nc = len(classes)\n",
    "    confmat = np.zeros((nc, nc)) \n",
    "    for ri in range(nc):\n",
    "        trues = (actual==classes[ri]).squeeze()\n",
    "        predictedThisClass = predicted[trues]\n",
    "        keep = trues\n",
    "        predictedThisClassAboveThreshold = predictedThisClass\n",
    "        # print 'confusionMatrix: sum(trues) is ', np.sum(trues),'for classes[ri]',classes[ri]\n",
    "        for ci in range(nc):\n",
    "            confmat[ri,ci] = np.sum(predictedThisClassAboveThreshold == classes[ci]) / float(np.sum(keep))\n",
    "    printConfusionMatrix(confmat,classes)\n",
    "    return confmat\n",
    "\n",
    "def printConfusionMatrix(confmat,classes):\n",
    "    print('   ',end='')\n",
    "    for i in classes:\n",
    "        print('%5d' % (i), end='')\n",
    "    print('\\n    ',end='')\n",
    "    print('{:s}'.format('------'*len(classes)))\n",
    "    for i,t in enumerate(classes):\n",
    "        print('{:2d} |'.format(t), end='')\n",
    "        for i1,t1 in enumerate(classes):\n",
    "            if confmat[i,i1] == 0:\n",
    "                print('  0  ',end='')\n",
    "            else:\n",
    "                print('{:5.1f}'.format(100*confmat[i,i1]), end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with toy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above data to compare QDA, LDA, and linear and nonlinear logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import qdalda\n",
    "qda = qdalda.QDA()\n",
    "qda.train(Xtrain, Ttrain)\n",
    "Ytrain = qda.use(Xtrain)\n",
    "Ytest = qda.use(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "print(np.hstack((Ttrain, Ytrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Ttrain == Ytrain) / len(Ttrain) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 2]\n",
      " [2 2]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "print(np.hstack((Ttest, Ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Ttest == Ytest) / len(Ttest) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = qdalda.LDA()\n",
    "lda.train(Xtrain, Ttrain)\n",
    "Ytrain = lda.use(Xtrain)\n",
    "Ytest = lda.use(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "print(np.hstack((Ttrain, Ytrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 2]\n",
      " [2 2]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "print(np.hstack((Ttest, Ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Ttrain == Ytrain) / len(Ttrain) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Ttest == Ytest) / len(Ttest) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1    2\n",
      "    ------------\n",
      " 1 |100.0  0  \n",
      " 2 |  0  100.0\n"
     ]
    }
   ],
   "source": [
    "ml.confusionMatrix(Ttrain, Ytrain, [1, 2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1    2\n",
      "    ------------\n",
      " 1 | 50.0 50.0\n",
      " 2 |  0  100.0\n"
     ]
    }
   ],
   "source": [
    "ml.confusionMatrix(Ttest, Ytest, [1, 2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(1, [5, 5], 2)\n",
      "   Network was trained for 101 iterations that took 0.2351 seconds. Final error is 3.041686791657381e-09.\n",
      "T, Predicted\n"
     ]
    }
   ],
   "source": [
    "netc = nn.NeuralNetworkClassifier(X.shape[1], [5, 5], len(np.unique(T)))\n",
    "netc.train(Xtrain, Ttrain, 100)\n",
    "print(netc)\n",
    "print('T, Predicted')\n",
    "Ytrain = netc.use(Xtrain)\n",
    "Ytest = netc.use(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "print(np.hstack((Ttrain, Ytrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [1 2]\n",
      " [2 2]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "print(np.hstack((Ttest, Ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Ttrain == Ytrain) / len(Ttrain) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Ttest == Ytest) / len(Ttest) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1    2\n",
      "    ------------\n",
      " 1 |100.0  0  \n",
      " 2 |  0  100.0\n"
     ]
    }
   ],
   "source": [
    "ml.confusionMatrix(Ttrain, Ytrain, [1, 2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1    2\n",
      "    ------------\n",
      " 1 | 50.0 50.0\n",
      " 2 |  0  100.0\n"
     ]
    }
   ],
   "source": [
    "ml.confusionMatrix(Ttest, Ytest, [1, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that linear logistic regression can be applied by specifying 0 hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(1, [], 2)\n",
      "   Network was trained for 101 iterations that took 0.1335 seconds. Final error is 1.3251306360973256e-05.\n",
      "T, Predicted\n"
     ]
    }
   ],
   "source": [
    "netc = nn.NeuralNetworkClassifier(X.shape[1], 0, len(np.unique(T)))\n",
    "netc.train(Xtrain, Ttrain, 100)\n",
    "print(netc)\n",
    "print('T, Predicted')\n",
    "Ytrain = netc.use(Xtrain)\n",
    "Ytest = netc.use(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1    2\n",
      "    ------------\n",
      " 1 |100.0  0  \n",
      " 2 |  0  100.0\n"
     ]
    }
   ],
   "source": [
    "ml.confusionMatrix(Ttrain, Ytrain, [1, 2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1    2\n",
      "    ------------\n",
      " 1 | 50.0 50.0\n",
      " 2 |  0  100.0\n"
     ]
    }
   ],
   "source": [
    "ml.confusionMatrix(Ttest, Ytest, [1, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to data from orthopedic patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download ```column_3C_weka.csv``` from [this Kaggle site](https://www.kaggle.com/uciml/biomechanical-features-of-orthopedic-patients).  Use the column named ```class``` to create your target class labels. Apply QDA, LDA, linear logistic regression, and nonlinear logistic regression to this data.  Experiment with different hidden layer structures and numbers of iterations and describe what you find.\n",
    "\n",
    "Partition data into 80% for training and 20% for testing, with ```shuffle=True```.\n",
    "\n",
    "Print percents of training and testing samples correctly classified by QDA, LDA and various neural network classifiers.  Also print confusion matrices for training and for testing samples for each classifier.  Discuss the relative performance of your classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading and Check-in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your notebook will be run and graded automatically. Test this grading process by first downloading [A4grader.tar](https://www.cs.colostate.edu/~anderson/cs445/notebooks/A4grader.tar) and extract A4grader.py from it.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================= Code Execution =======================\n",
      "\n",
      "========================RUNNING INSTRUCTORS SOLUTION!\n",
      "\n",
      "Testing  import neuralnetworksA4 as nn\n",
      "\n",
      "--- 5/5 points. The statement  import neuralnetworksA4 as nn  works.\n",
      "\n",
      "Testing  import mlutilities as ml\n",
      "\n",
      "--- 5/5 points. The statement  import mlutilities as ml  works.\n",
      "\n",
      "Testing X = np.vstack((np.arange(20), [7, 4, 5, 5, 8, 4, 6, 7, 4, 9, 4, 2, 6, 6, 3, 3, 7, 2, 6, 4])).T\n",
      "        T = np.array([1]*8 + [2]*8 + [3]*4).reshape((-1, 1))\n",
      "        Xtrain, Ttrain, Xtest, Ttest = ml.partition(X, T, 0.8, classification=True, shuffle=False)\n",
      "\n",
      "--- 10/10 points. ml.partition works correctly\n",
      "\n",
      "Testing nnet = nn.NeuralNetworkClassifier(2, [5, 5], 3)\n",
      "\n",
      "--- 10/10 points. nn.NeuralNetworkClassifier did not throw exception.\n",
      "\n",
      "Testing nnet.train(Xtrain, Ttrain, 200)\n",
      "\n",
      "--- 20/20 points. nnet.getErrors()[-1] is less than 1.e-5.\n",
      "\n",
      "Testing Ytest = nnet.use(Xtest)\n",
      "        fractionCorrect = np.sum(Ytest == Ttest) / len(Ttest)\n",
      "\n",
      "--- 20/20 points. fractionCorrect is correct with value of 0.6.\n",
      "\n",
      "Testing Ytest, Yprobs, Z = nnet.use(Xtest, allOutputs=True)\n",
      "\n",
      "--- 10/10 points. np.sum(Yprobs, axis=1) is correct: are all very close to 1.\n",
      "\n",
      "A4 Execution Grade is 80/80\n",
      "\n",
      "============= Experiments with Orthopedic Data =============\n",
      "\n",
      "--- __/5 points. Results for QDA, including percents correct and confusion matrices.\n",
      "                Comments:\n",
      "\n",
      "--- __/5 points. Results for LDA, including percents correct and confusion matrices.\n",
      "                Comments:\n",
      "\n",
      "--- __/5 points. Results for several neural networks, including percents correct and confusion matrices.\n",
      "                Comments:\n",
      "\n",
      "--- __/5 points. Discussion of relative performance among classifiers, and among the different classes\n",
      "                Comments:\n",
      "\n",
      "A4 Notebook Grade is __ / 20\n",
      "\n",
      "A4 FINAL GRADE is __ / 100\n",
      "\n",
      "A4 EXTRA CREDIT POINTS  __ / 1\n"
     ]
    }
   ],
   "source": [
    "%run -i A4grader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earn 1 extra credit point by doing a few experiments with different neural network classifiers using the ReLU activation function on the orthopedic data. Discuss any differences you see from your earlier results that used tanh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
